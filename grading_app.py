import os
import json
import textwrap
import pandas as pd
import streamlit as st
from dotenv import load_dotenv
load_dotenv()
from openai import OpenAI


# UI

st.set_page_config(page_title="Course Grade Recommender", layout="wide")

st.sidebar.title("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")
model_default = "gpt-4.1-mini"  # –±–µ–∑–æ–ø–∞—Å–Ω—ã–π –±—ã—Å—Ç—Ä—ã–π –¥–µ—Ñ–æ–ª—Ç; –º–æ–∂–Ω–æ —Å–º–µ–Ω–∏—Ç—å –≤ UI
model = st.sidebar.text_input("–ú–æ–¥–µ–ª—å OpenAI", value=model_default, help="–ù–∞–ø—Ä.: gpt-4.1, gpt-4o, gpt-4.1-mini, gpt-5 (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–∞ –≤ –≤–∞—à–µ–º –∞–∫–∫–∞—É–Ω—Ç–µ)")
shots_per_class = st.sidebar.slider("–ö–æ–ª-–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –Ω–∞ –∫–ª–∞—Å—Å (few-shot)", 1, 8, 3)
max_train_rows = st.sidebar.slider("–ú–∞–∫—Å. —Å—Ç—Ä–æ–∫ –∏–∑ CSV –¥–ª—è –ø—Ä–∏–º–µ—Ä–æ–≤ (–ø–µ—Ä–µ–º–µ—à–∞–Ω–Ω—ã—Ö)", 100, 5000, 1000, step=100)
strict_json = st.sidebar.checkbox("–°—Ç—Ä–æ–≥–∏–π JSON-–≤—ã–≤–æ–¥ (Structured Outputs)", value=True)

st.sidebar.caption("–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç OpenAI **Responses API** –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤—ã–≤–æ–¥ JSON –¥–ª—è –Ω–∞–¥—ë–∂–Ω–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ–ª–∏.")

# API
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    st.warning("–ù–µ –Ω–∞–π–¥–µ–Ω ENV-–ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è OPENAI_API_KEY. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –µ—ë –ø–µ—Ä–µ–¥ –∑–∞–ø—Ä–æ—Å–æ–º –∫ LLM.")
client = OpenAI(api_key=OPENAI_API_KEY)  # openai>=1.0.0

# –≥–ª. –∫–æ–ª–æ–Ω–∫–∞
st.title("üéì –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è –≥—Ä–µ–π–¥–∞")
st.write(
    "–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏—Å—Ö–æ–¥–Ω—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö (CSV —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ **course_name**, **summary**, **category_name**, **course_structure**, **recommended_grade**), "
    "–∑–∞—Ç–µ–º –≤–≤–µ–¥–∏—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –∫—É—Ä—Å–∞ ‚Äî –ø–æ–ª—É—á–∏—Ç–µ `recommended_grade`"
)

uploaded = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ andersen_clean_for_LLM", type=["csv"])

col1, col2 = st.columns(2)
with col1:
    course_name = st.text_input("–ù–∞–∑–≤–∞–Ω–∏–µ –∫—É—Ä—Å–∞ (course_name)", "")
    category_name = st.text_input("–ö–∞—Ç–µ–≥–æ—Ä–∏—è (category_name)", "")
with col2:
    summary = st.text_area("–ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ (summary)", "", height=120)
    course_structure = st.text_area("–°—Ç—Ä—É–∫—Ç—É—Ä–∞/–º–æ–¥—É–ª—å–Ω–æ—Å—Ç—å (course_structure)", "", height=120)

run_btn = st.button("üîÆ –ü–æ–ª—É—á–∏—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π –≥—Ä–µ–π–¥", type="primary")

# --------------------------
# –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
# --------------------------
def clean_str(x):
    if pd.isna(x):
        return ""
    return str(x).strip()

def pick_few_shots(df, label_col="recommended_grade", k=3, seed=42):
    # –ì–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ –±–µ—Ä—ë–º –¥–æ k –ø—Ä–∏–º–µ—Ä–æ–≤ –Ω–∞ –∫–ª–∞—Å—Å
    # –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –ø–µ—Ä–µ–º–µ—à–∞–≤ –¥–∞—Ç–∞—Å–µ—Ç
    dfx = df.sample(frac=1.0, random_state=seed).copy()
    examples = []
    for cls, grp in dfx.groupby(label_col):
        take = grp.head(k)
        for _, r in take.iterrows():
            ex = {
                "course_name": clean_str(r.get("course_name", "")),
                "summary": clean_str(r.get("summary", "")),
                "category_name": clean_str(r.get("category_name", "")),
                "course_structure": clean_str(r.get("course_structure", "")),
                "recommended_grade": clean_str(r.get(label_col, "")),
            }
            # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ —Ü–µ–ª–µ–≤—ã–µ
            if ex["recommended_grade"] == "":
                continue
            examples.append(ex)
    return examples

def build_system_prompt(allowed_labels):
    return textwrap.dedent(f"""
    –í—ã ‚Äî –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ø–æ –ø—Ä–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—é –≥—Ä–µ–π–¥–æ–≤ –∫—É—Ä—Å–∞–º –¥–ª—è IT-—Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–æ–≤, –≤–∞—à–∞ –∑–∞–¥–∞—á–∞ ‚Äî –ø—Ä–∏—Å–≤–æ–∏—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π –≥—Ä–µ–π–¥ –∫—É—Ä—Å—É.
    –û—Ç–≤–µ—á–∞–π—Ç–µ —Å—Ç—Ä–æ–≥–æ –≤ JSON —Å –ø–æ–ª—è–º–∏:
      - "recommended_grade": –æ–¥–∏–Ω –∏–∑ {allowed_labels}. J - junor, M - middle, S - senior, All - all levels.
      - "confidence": —á–∏—Å–ª–æ –æ—Ç 0 –¥–æ 1 (–æ—Ü–µ–Ω–∫–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏)
      - "explanation": –∫—Ä–∞—Ç–∫–æ, 1‚Äì2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, –ø–æ—á–µ–º—É –≤—ã–±—Ä–∞–Ω —ç—Ç–æ—Ç –≥—Ä–µ–π–¥ (–±–µ–∑ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –ø–æ —à–∞–≥–∞–º).

    –ü—Ä–∞–≤–∏–ª–∞:
    - –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø—Ä–∏–º–µ—Ä—ã (few-shot) –∫–∞–∫ –æ—Ä–∏–µ–Ω—Ç–∏—Ä —Å—Ç–∏–ª—è –∏ –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤.
    - –ï—Å–ª–∏ –æ–ø–∏—Å–∞–Ω–∏–µ —Å–∫—É–¥–Ω–æ–µ, –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–π—Ç–µ –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω–µ–µ –∏ —Å–Ω–∏–∂–∞–π—Ç–µ "confidence".
    - –ù–µ –≤—ã–¥—É–º—ã–≤–∞–π—Ç–µ –Ω–æ–≤—ã—Ö –º–µ—Ç–æ–∫.
    """).strip()

def build_user_prompt(new_item, few_shots):
    # –°—Ñ–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–º–ø–∞–∫—Ç–Ω—ã–π –ø—Ä–æ–º–ø—Ç: —Å–Ω–∞—á–∞–ª–∞ –ø—Ä–∏–º–µ—Ä—ã, –∑–∞—Ç–µ–º –Ω–æ–≤—ã–π –∫—É—Ä—Å
    lines = []
    lines.append("–ü—Ä–∏–º–µ—Ä—ã (–∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –∑–∞–ø–∏—Å–∏, —Ñ–æ—Ä–º–∞—Ç JSONLines):")
    for ex in few_shots:
        lines.append(json.dumps(ex, ensure_ascii=False))
    lines.append("\n–ù–æ–≤—ã–π –∫—É—Ä—Å:")
    lines.append(json.dumps(new_item, ensure_ascii=False))
    lines.append("\n–í–µ—Ä–Ω–∏—Ç–µ —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω JSON-–æ–±—ä–µ–∫—Ç —Å –ø–æ–ª—è–º–∏ recommended_grade, confidence, explanation.")
    return "\n".join(lines)

def call_llm_responses_api(model, system, user, temperature=0.2, strict=True):
    if not strict:
        # –ù–µ—Å—Ç—Ä–æ–≥–∏–π —Ä–µ–∂–∏–º: –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ—Å–∏–º JSON, –ø–∞—Ä—Å–∏–º –Ω–∞ –Ω–∞—à–µ–π —Å—Ç–æ—Ä–æ–Ω–µ
        resp = client.responses.create(
            model=model,
            input=[
                {"role": "system", "content": system},
                {"role": "user", "content": user},
            ],
        )
        text = resp.output_text
        return text
    else:
        # –°—Ç—Ä–æ–≥–∏–π JSON —á–µ—Ä–µ–∑ Structured Outputs (json_schema)
        schema = {
            "name": "grade_schema",
            "schema": {
                "type": "object",
                "properties": {
                    "recommended_grade": {"type": "string"},
                    "confidence": {"type": "number"},
                    "explanation": {"type": "string"}
                },
                "required": ["recommended_grade", "confidence", "explanation"],
                "additionalProperties": False
            },
            "strict": True
        }
        resp = client.chat.completions.create(
        model=model,
        response_format={"type": "json_schema", "json_schema": schema},
        messages=[
            {"role": "system", "content": system},
            {"role": "user", "content": user},
            ],
        )
        return resp.choices[0].message.content

def parse_llm_json(s):
    try:
        return json.loads(s)
    except Exception:
        # –ø–æ–ø—ã—Ç–∫–∞ –≤—ã–¥–µ—Ä–Ω—É—Ç—å JSON-–æ–±—ä–µ–∫—Ç –∏–∑ —Ç–µ–∫—Å—Ç–∞
        start = s.find("{")
        end = s.rfind("}")
        if start >= 0 and end > start:
            try:
                return json.loads(s[start:end+1])
            except Exception:
                return None
        return None

# --------------------------
# –û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞
# --------------------------
if run_btn:
    if uploaded is None:
        st.error("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ CSV —Å –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏ ")
        st.stop()

    try:
        df = pd.read_csv(uploaded)
    except Exception as e:
        st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å CSV: {e}")
        st.stop()

    required_cols = ["course_name", "summary", "category_name", "course_structure", "recommended_grade"]
    missing = [c for c in required_cols if c not in df.columns]
    if missing:
        st.error(f"–í CSV –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {missing}")
        st.stop()

    # –ü—Ä–µ–¥–æ—á–∏—Å—Ç–∫–∞ –∏ –ø–æ–¥—Ä–µ–∑–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞
    df = df[required_cols].copy()
    if len(df) > max_train_rows:
        df = df.sample(n=max_train_rows, random_state=42)

    # –°–ø–∏—Å–æ–∫ –¥–æ–ø—É—Å—Ç–∏–º—ã—Ö –º–µ—Ç–æ–∫
    labels = (
        df["recommended_grade"].astype(str).fillna("").str.strip().replace({"": "nan"}).unique().tolist()
    )
    # –ú–∏–Ω–∏-–≥–∞—Ä–º–æ–Ω–∏–∑–∞—Ü–∏—è: —É–±—Ä–∞—Ç—å 'nan' —Ä–∞–∑–Ω—ã—Ö —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–π
    labels = sorted(set(["nan" if str(x).lower() in {"nan", "none"} else str(x) for x in labels]))
    allowed_labels_str = ", ".join([f'"{x}"' for x in labels])

    # Few-shot –ø—Ä–∏–º–µ—Ä—ã
    shots = pick_few_shots(df.assign(
        course_name=df["course_name"].map(clean_str),
        summary=df["summary"].map(clean_str),
        category_name=df["category_name"].map(clean_str),
        course_structure=df["course_structure"].map(clean_str),
        recommended_grade=df["recommended_grade"].astype(str).map(lambda x: "nan" if x.strip()=="" else x.strip())
    ), k=shots_per_class)

    if len(shots) == 0:
        st.error("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–±—Ä–∞—Ç—å few-shot –ø—Ä–∏–º–µ—Ä—ã (–≤–æ–∑–º–æ–∂–Ω–æ, –ø—É—Å—Ç—ã–µ –∏–ª–∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –º–µ—Ç–∫–∏).")
        st.stop()

    # –ù–æ–≤—ã–π –æ–±—ä–µ–∫—Ç
    new_item = {
        "course_name": clean_str(course_name),
        "summary": clean_str(summary),
        "category_name": clean_str(category_name),
        "course_structure": clean_str(course_structure),
    }

    if all(v == "" for v in new_item.values()):
        st.error("–í–≤–µ–¥–∏—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –∫—É—Ä—Å–∞ (–º–∏–Ω–∏–º—É–º –æ–¥–Ω–æ –ø–æ–ª–µ).")
        st.stop()

    # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–æ–≤
    system_prompt = build_system_prompt(allowed_labels=allowed_labels_str)
    user_prompt = build_user_prompt(new_item=new_item, few_shots=shots)

    # –í—ã–∑–æ–≤ LLM
    try:
        raw = call_llm_responses_api(
            model=model,
            system=system_prompt,
            user=user_prompt,
            strict=strict_json
        )
    except Exception as e:
        st.exception(e)
        st.stop()

    result = parse_llm_json(raw) if isinstance(raw, str) else raw
    st.subheader("üß† –û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏")
    st.code(raw, language="json")

    if isinstance(result, dict):
        rg = result.get("recommended_grade", "").strip()
        conf = result.get("confidence", None)
        expl = result.get("explanation", "")

        # –ø–æ–¥—Å–≤–µ—Ç–∏–º –ø–ª–∞—à–∫–æ–π
        st.success(f"**recommended_grade:** {rg}")
        if conf is not None:
            try:
                st.progress(min(max(float(conf), 0.0), 1.0))
            except Exception:
                pass
        if expl:
            st.write(f"**–ü–æ—è—Å–Ω–µ–Ω–∏–µ:** {expl}")

        # –°—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å —Å—Ç—Ä–æ–∫—É –¥–ª—è –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è
        st.download_button(
            "üíæ –°–∫–∞—á–∞—Ç—å JSON-—Ä–µ–∑—É–ª—å—Ç–∞—Ç",
            data=json.dumps(result, ensure_ascii=False, indent=2),
            file_name="recommended_grade.json",
            mime="application/json"
        )
    else:
        st.warning("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –±–ª–æ–∫ –≤—ã—à–µ ‚Äî —Ç–∞–º –µ—Å—Ç—å —Å—ã—Ä–æ–π –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏.")

# --------------------------
# –ù–∏–∂–Ω—è—è —Å–ø—Ä–∞–≤–∫–∞
# --------------------------
with st.expander("‚ÑπÔ∏è –ü–æ–¥—Å–∫–∞–∑–∫–∏ –ø–æ –∫–∞—á–µ—Å—Ç–≤—É"):
    st.markdown("""
- –ß–µ–º –±–æ–≥–∞—á–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∫—É—Ä—Å–∞, —Ç–µ–º –≤—ã—à–µ —Ç–æ—á–Ω–æ—Å—Ç—å. –ó–∞–ø–æ–ª–Ω—è–π—Ç–µ –≤—Å–µ –ø–æ–ª—è.
- –£–≤–µ–ª–∏—á—å—Ç–µ `–ö–æ–ª-–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –Ω–∞ –∫–ª–∞—Å—Å` –≤ —Å–∞–π–¥–±–∞—Ä–µ, –µ—Å–ª–∏ –∫–ª–∞—Å—Å—ã –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω—ã.
- –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –ø—É—Ç–∞–µ—Ç –∫–ª–∞—Å—Å—ã —Å —Ä–µ–¥–∫–∏–º–∏ –ø—Ä–∏–º–µ—Ä–∞–º–∏, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ:
  - –ø–æ–≤—ã—Å–∏—Ç—å shots –¥–æ 5‚Äì8;
  - —Å–æ–∫—Ä–∞—Ç–∏—Ç—å `–ú–∞–∫—Å. —Å—Ç—Ä–æ–∫` –¥–æ –±–æ–ª–µ–µ —Ä–µ–ø—Ä–µ–∑–µ–Ω—Ç–∞—Ç–∏–≤–Ω–æ–π –ø–æ–¥–≤—ã–±–æ—Ä–∫–∏ –∏–ª–∏ –Ω–∞–æ–±–æ—Ä–æ—Ç —É–≤–µ–ª–∏—á–∏—Ç—å.
- –ú–æ–∂–Ω–æ –∑–∞–¥–∞—Ç—å –±–æ–ª–µ–µ –º–æ—â–Ω—É—é –º–æ–¥–µ–ª—å –≤ –ø–æ–ª–µ **–ú–æ–¥–µ–ª—å OpenAI** (–µ—Å–ª–∏ –µ—Å—Ç—å –¥–æ—Å—Ç—É–ø).
""")
